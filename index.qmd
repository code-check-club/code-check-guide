# Introduction

```{r cite-packages, include = FALSE}
# automatically create a bib database for R packages
# add any packages you want to cite here
knitr::write_bib(c(
  #.packages(), 
  #'tidyverse'
), 'include/packages.bib')

source("R/setup.R")
```


## What is code check?

### Why is it important?

- Reproducibility checks
- Everyone will inevitably make mistakes. We should have a system to catch them

### Why don't people do it?

- Lack of time 
- Not seen as a priority
- Lack of expertise
- Embarrassed for others to see their code
- Lack of incentives - error-mitigating procedures are weakly related to chances of publishing
- Errors might be noticed, leading to retractions and corrections.

### What specific problems does this guide address?

- Time: help to prioritise review tasks for allotted time
- Priority: clearly explain how review makes science better
- Expertise: explain what type of code check can be done at different levels of expertise; signpost resources for developing appropriate expertise
- Embarrassment: tips for code writers to make them more confident about showing their work to others
- How to give and get credit for code review
- Increase and diversify the pool of potential reviewers


## Who is this guide for?

### Expertise

- Novice to intermediate experience with research code (you should at least be able to write an analysis script in the language you're checking)
- Mainly end users, no assumption of a computer science background
- No assumption that you know git/github
- Coding language agnostic (but examples in R and python?)

### Roles

- Code reviewers
- Code writers to prep code for others to review
- Checklist for self-check (when others don’t have time/expertise)


## What are the goals?

### Goals of code checking in general


#### Does it run? 

Can a researcher who uses that language run it easily, are any unusual or complex procedures explained?

#### Is it reproducible?

Do you get the same outputs? Is it straightforward to check them?

#### Is it auditable/understandable? 

Even if you don’t have the expertise to assess the stats or data processing, is the code well-organised enough to figure out what is intended so mistakes *could* be detected? Are the outputs sufficiently detailed to allow interrogation?

#### Does it follow best practices?

Is there too much repeated code that could benefit from modularisation? DRY (Don’t repeat yourself) and SPOT (Single Point of Truth)? Are the outputs of long processes saved and loaded from file? Are there unit tests? Do the variable names make sense?  Do the results match what is shown in the output and there is no rounding up or down?

#### Is it correct and appropriate?

Is the code actually doing what is intended? Is what is intended correct? Some logical problems can be caught without domain knowledge, such as intending to to filter out male subjects, but actually filtering them IN. Many other problems require domain and/or statistical knowledge, so may only be appropriate in some circumstances. 

### What are NOT goals of code check

#### Debugging

Do not submit code that doesn’t run for you

#### Code Help

Don’t expect the reviewer to create code for you

#### Stats Consulting

Do not rely on code check to assess the appropriateness of your scientific decisions or statistical analyses

### Goals in this guide

- Main focus on the first 3 goals above (runnable, reproducible, auditable)
- Maybe best practices in an appendix?
- We won’t focus much on the last one, as it requires stats/domain knowledge

## How to use this guide

You can go through the Checklists for different situations. Each step is linked to further explanation in the Topics section is a step is unfamiliar to you.


